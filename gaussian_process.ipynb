{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gaussian Processes\n",
    "\n",
    "Gaussian process is an infinite collection of random variables, any finite number of which have a joint Gaussian distribution (due to consistency or marginalisation property of Gaussian distributions).\n",
    "\n",
    "Task is to infer the function $f(\\cdot)$ from a data $\\mathcal{D}=\\{y_i,x_i\\}_{i=1}^N$: $y_i=f(x_i) + \\epsilon$ where $\\epsilon$ is Gaussian i.i.d noise with variance $\\sigma_n^2$\n",
    "\n",
    "Likelihood for indendent data: $p(y|f(x))=\\prod_{i=1}^N p(y_i|f(x_i))$\n",
    "\n",
    "GP prior over functions evaluated at the input locations which are jointly Gaussian:\n",
    "\n",
    "$$\\begin{bmatrix}f_1 \\\\ f_2 \\\\ \\vdots \\\\ f_N \\end{bmatrix} \\sim \\mathcal{N}\\ \\left(\\begin{bmatrix}\\mu_1 \\\\ \\mu_2 \\\\ \\vdots \\\\ \\mu_N \\end{bmatrix},\\begin{bmatrix}k(x_1,x_1) +\\sigma_n^2 I & k(x_1,x_2) & \\dots & k(x_1,x_N) \\\\ k(x_2,x_1) & k(x_2,x_2) +\\sigma_n^2 I & \\dots & k(x_2,x_N) \\\\ \\vdots & \\vdots & \\dots & \\vdots \\\\ k(x_N,x_1) & k(x_N,x_2) & \\dots & k(x_N,x_N) +\\sigma_n^2 I \\end{bmatrix}\\right)$$\n",
    "\n",
    "Where $\\mu(\\cdot)$ is the mean function and $k(\\cdot,\\cdot)$ is the co-variance function or kernel. One example of a kernel is the squared exponential: $k(x,x^\\prime)=\\sigma^2 exp \\left(\\frac{-(x-x^\\prime)^T(x-x^\\prime)}{l^2}\\right)$\n",
    "\n",
    "Joint distribution of the training outputs $f$ and test outputs $f_*$ according to the prior is:\n",
    "\n",
    "$$\\begin{bmatrix}f \\\\ f_* \\end{bmatrix} \\sim \\mathcal{N}\\ \\left(0, \\begin{bmatrix}k(X,X) +\\sigma_n^2 I & k(X,X_*) \\\\ k(X_*,X) & k(X_*,X_*) \\end{bmatrix}\\right)$$\n",
    "\n",
    "The posterior is found by conditioning the joint Gaussian prior distribution on the observations: $p(f_*|f,X_*,X) = \\mathcal{N}(\\mu_{X_*|X},K_{X_*|X})$ where $\\mu_{X_*|X}=k(x_*,x)(k(x,x)+\\sigma_n^2I)^{-1}f$ and $K_{X_*|X}=k(x_*,x_*)-k(x_*,x)(k(x,x)+\\sigma_n^2I)^{-1}k(x,x_*)$\n",
    "\n",
    "To tune the kernel hyperparameters ($l, \\sigma^2, \\sigma_n^2$) then maximise the marginal log likelihood: $log\\ p(f|X)=-\\frac12 f^T(k+\\sigma_n^2 I)^{-1}f - \\frac12 log|k+\\sigma_n^2| -\\frac{n}{2} log 2\\pi$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/xq/vn60xb7s2cd4ggcbjcn35s4dpzfmr3/T/ipykernel_52571/816101552.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpatches\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mEllipse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstats\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnorm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy.stats import norm\n",
    "from scipy.spatial.distance import cdist\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_gaussian(mu, sigma, n_std=2):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    samples = np.random.multivariate_normal(mu, sigma, 1000)\n",
    "    ax.scatter(samples[:, 0], samples[:, 1], s=10)\n",
    "    lam, u = np.linalg.eig(sigma)\n",
    "    theta = np.arctan(u[0, 0] / (u[1, 0])+1e-10) / (2*np.pi) * 360\n",
    "    for i in range(1, n_std+1):\n",
    "        ellipse = Ellipse((mu[0], mu[1]), width=2*lam[0]**(1/2)*i, height=2*lam[1]**(1/2)*i,\n",
    "                          angle=theta, fill=None)\n",
    "        ax.add_patch(ellipse)\n",
    "    ax.set_xlim(-4, 4), ax.set_ylim(-4, 4)\n",
    "    ax.set_xlabel(\"x1\"), ax.set_ylabel(\"x2\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu = np.array([0,0])\n",
    "sigma = np.array([[1,0],[0,1]])\n",
    "plot_gaussian(mu, sigma, n_std=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sigma = np.array([[1,0.7],[0.7,1]])\n",
    "plot_gaussian(mu, sigma, n_std=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_conditioning(mu, sigma, cond_dim, cond_value, n_std=3):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    lam, u = np.linalg.eig(sigma)\n",
    "    theta = np.arctan(u[0, 0] / (u[1, 0])+1e-10) / (2*np.pi) * 360\n",
    "    for i in range(1, n_std+1):\n",
    "        ellipse = Ellipse((mu[0], mu[1]), width=2*lam[0]**(1/2)*i, height=2*lam[1]**(1/2)*i,\n",
    "                          angle=theta, fill=None)\n",
    "        ax1.add_patch(ellipse)\n",
    "    ax1.set_xlim(-4, 4), ax1.set_ylim(-4, 4)\n",
    "    ax1.set_xlabel(\"x1\"), ax1.set_ylabel(\"x2\")\n",
    "\n",
    "    plot_dim = 1 - cond_dim\n",
    "    cond_line = np.array([[cond_value, cond_value], [-4, 4]])\n",
    "    ax1.plot(cond_line[cond_dim, :], cond_line[plot_dim, :])\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    ax2.plot(x, norm.pdf(x, loc=mu[plot_dim], scale=sigma[plot_dim, plot_dim]),\n",
    "             label=f\"p(x{plot_dim+1})\")\n",
    "    cond_mu = mu[plot_dim] + sigma[plot_dim, cond_dim] * float(sigma[cond_dim, cond_dim])**-1 * \\\n",
    "              (cond_value - mu[cond_value])\n",
    "    cond_sigma = sigma[plot_dim, plot_dim] - sigma[plot_dim, cond_dim] * \\\n",
    "                 float(sigma[cond_dim, cond_dim])**-1 * sigma[cond_dim, plot_dim]\n",
    "    ax2.plot(x, norm.pdf(x, loc=cond_mu, scale=cond_sigma),\n",
    "             label=f\"p(x{plot_dim+1}|x{cond_dim+1}={cond_value})\")\n",
    "    ax2.set_xlabel(f\"x{plot_dim+1}\")\n",
    "    ax2.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu = np.array([0, 0])\n",
    "sigma = np.array([[1, 0.7], [0.7, 1]])\n",
    "plot_conditioning(mu, sigma, cond_dim=1, cond_value=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sigma = np.array([[1, 0.3], [0.3, 1]])\n",
    "plot_conditioning(mu, sigma, cond_dim=1, cond_value=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sigma = np.array([[1, 0.9], [0.9, 1]])\n",
    "plot_conditioning(mu, sigma, cond_dim=1, cond_value=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_plot(mu, sigma, n_sam=10):\n",
    "    dim = len(mu)\n",
    "    assert type(dim) is int and dim > 1\n",
    "\n",
    "    samples = np.random.multivariate_normal(mu, sigma, n_sam)\n",
    "    if dim == 2:\n",
    "        fig, (ax1, ax) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        lam, u = np.linalg.eig(sigma)\n",
    "        theta = np.arctan(u[0, 0] / (u[1, 0])+1e-10) / (2*np.pi) * 360\n",
    "        for i in range(1, 4):\n",
    "            ellipse = Ellipse((mu[0], mu[1]), width=2*lam[0]**(1/2)*i, height=2*lam[1]**(1/2)*i,\n",
    "                              angle=theta, fill=None)\n",
    "            ax1.add_patch(ellipse)\n",
    "        ax1.set_xlim(-4, 4), ax1.set_ylim(-4, 4)\n",
    "        ax1.set_xlabel(\"x1\"), ax1.set_ylabel(\"x2\")\n",
    "        prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "        colors = prop_cycle.by_key()['color']\n",
    "        ax1.scatter(samples[:, 0], samples[:, 1], c=colors[:n_sam])\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    ax.plot(np.tile(np.arange(1, dim+1), reps=(n_sam, 1)).T, samples.T, marker='o')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu = np.zeros(2)\n",
    "sigma = np.array([[1, 0.99], [0.99, 1]])\n",
    "sample_plot(mu, sigma, n_sam=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sigma = np.array([[1, 0.3], [0.3, 1]])\n",
    "sample_plot(mu, sigma, n_sam=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu = np.zeros(5)\n",
    "sigma = np.array(\n",
    "    [[1, 0.9, 0.8, 0.6, 0.4],\n",
    "     [0.9, 1, 0.9, 0.8, 0.6],\n",
    "     [0.8, 0.9, 1, 0.9, 0.8],\n",
    "     [0.6, 0.8, 0.9, 1, 0.9],\n",
    "     [0.4, 0.6, 0.8, 0.9, 1]\n",
    "     ])\n",
    "sample_plot(mu, sigma, 10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_plot_with_cond(mu, sigma, n_sam=10, cond_dim=np.array([0]), cond_value=np.array([0])):\n",
    "    dim = len(mu)\n",
    "    assert dim > 2\n",
    "    other_dims = np.arange(len(cond_dim), dim)\n",
    "\n",
    "    if len(cond_dim) == 1:\n",
    "        mu = mu[other_dims] + sigma[other_dims, cond_dim] *\\\n",
    "                  float(sigma[cond_dim, cond_dim])**-1 * (cond_value - mu[cond_dim])\n",
    "        sigma = sigma[other_dims][:, other_dims] - sigma[other_dims, cond_dim].reshape(-1, 1) @ \\\n",
    "                (float(sigma[cond_dim, cond_dim])**-1 * sigma[cond_dim, other_dims].reshape(1, -1))\n",
    "    else:\n",
    "        mu = mu[other_dims] + sigma[other_dims][:, cond_dim] @ \\\n",
    "             np.linalg.inv(sigma[cond_dim][:, cond_dim]) @ (cond_value - mu[cond_dim])\n",
    "        sigma = sigma[other_dims][:, other_dims] - sigma[other_dims][:, cond_dim] @ \\\n",
    "                np.linalg.inv(sigma[cond_dim][:, cond_dim]) @ sigma[cond_dim][:, other_dims]\n",
    "\n",
    "    samples = np.random.multivariate_normal(mu.flatten(), sigma, n_sam)\n",
    "    samples = np.concatenate((np.tile(cond_value, reps=(n_sam, 1)), samples), axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.plot(np.tile(np.arange(1, dim+1), reps=(n_sam, 1)).T, samples.T, marker='o')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu = np.zeros(3)\n",
    "sigma = np.array([[1, 0.9, 0.6], [0.9, 1, 0.9], [0.6, 0.9, 1]])\n",
    "sample_plot_with_cond(mu, sigma, n_sam=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu = np.zeros(5)\n",
    "sigma = np.array(\n",
    "    [[1, 0.9, 0.8, 0.6, 0.4],\n",
    "     [0.9, 1, 0.9, 0.8, 0.6],\n",
    "     [0.8, 0.9, 1, 0.9, 0.8],\n",
    "     [0.6, 0.8, 0.9, 1, 0.9],\n",
    "     [0.4, 0.6, 0.8, 0.9, 1]\n",
    "     ])\n",
    "sample_plot_with_cond(mu, sigma, n_sam=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_plot_with_cond(mu, sigma, n_sam=10, cond_dim=np.array([0, 1]), cond_value=np.array([0, 0.2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rbf_kernel(var, l):\n",
    "    return lambda x1, x2: var * np.exp(-np.power(cdist(x1, x2), 2) / l**2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kernel = rbf_kernel(var=1, l=5)\n",
    "size = 20\n",
    "x = np.arange(1, size+1).reshape(-1, 1)\n",
    "cov = kernel(x, x)\n",
    "plt.imshow(cov, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_plot(np.zeros(len(cov)), cov)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_plot_with_cond(np.zeros(len(cov)), cov)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_plot_with_cond(np.zeros(len(cov)), cov, cond_dim=np.array([0, 1]),\n",
    "                      cond_value=np.array([0, 0.2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "size = 200\n",
    "x = np.linspace(-2, 2, size).reshape(-1, 1)\n",
    "kernel = rbf_kernel(var=2, l=0.4)\n",
    "cov = kernel(x, x)\n",
    "n_sam = 20\n",
    "samples = np.random.multivariate_normal(np.zeros(len(cov)), cov, n_sam)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.plot(np.tile(x, reps=(1, n_sam)), samples.T)\n",
    "ax.set_xlim(-1.5, 1.5)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10\n",
    "x = np.concatenate((np.ones((n, 1)), np.linspace(-1, 1, n).reshape(-1, 1)), axis=1)\n",
    "w = np.array([-0.1, 0.8])\n",
    "var_gen = 0.2\n",
    "y = np.random.normal(x @ w, var_gen, x.shape[0])\n",
    "var_n = 0.1\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.set_xlim(-1.5, 1.5), ax.set_ylim(-1.5, 1.5)\n",
    "ax.scatter(x[:, 1], y, s=100)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_star = np.linspace(-1.5, 1.5, 500).reshape(-1, 1)\n",
    "\n",
    "def gp_prediction(x, y, x_star, kernel, var_n):\n",
    "    mu = kernel(x_star, x) @ np.linalg.inv(kernel(x, x) + var_n * np.identity(len(x))) @ y\n",
    "    cov = kernel(x_star, x_star) - kernel(x_star, x) @ np.linalg.inv(kernel(x, x) + var_n * np.identity(len(x))) @ kernel(x, x_star)\n",
    "    return mu, cov\n",
    "\n",
    "n_sam = 20\n",
    "idx = np.random.permutation(np.arange(len(x)))[:5]\n",
    "for i in range(1, len(idx)):\n",
    "    x_sam = x[idx[:i], 1].reshape(-1, 1)\n",
    "    y_sam = y[idx[:i]]\n",
    "    mu, cov = gp_prediction(x_sam, y_sam, x_star, kernel, var_n)\n",
    "    fig, (ax, ax2) = plt.subplots(1, 2, figsize=(20, 5), gridspec_kw={'width_ratios': [3, 1]})\n",
    "    samples = np.random.multivariate_normal(mu, cov, n_sam)\n",
    "    ax.scatter(x_sam, y_sam, s=100)\n",
    "    ax.plot(np.tile(x_star, reps=(1, n_sam)), samples.T, alpha=0.6)\n",
    "    ax2.imshow(cov, cmap='hot', interpolation='nearest')\n",
    "    ax.set_xlim(-1.5, 1.5)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "mu, cov = gp_prediction(x[:, 1].reshape(-1, 1), y, x_star, kernel, var_n)\n",
    "ax.plot(x_star, mu)\n",
    "ax.fill_between(x_star.flatten(), mu-np.diag(cov), mu+np.diag(cov), alpha=0.3)\n",
    "ax.set_xlim(-1.5, 1.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def torch_rbf_kernel(var, l):\n",
    "    return lambda x1, x2: var * torch.exp(-torch.pow(torch.cdist(x1, x2), 2) / l**2)\n",
    "\n",
    "def marg_log_likelihood(x, y, kernel, var_n):\n",
    "    k_n = kernel(x, x) + var_n * torch.eye(len(x))\n",
    "    return  - 1/2 * y.T @ torch.inverse(k_n)  @ y - 1/2 * torch.log(torch.norm(k_n)) - len(x)/2 * torch.log(torch.tensor(2*torch.pi))\n",
    "\n",
    "x_torch = torch.as_tensor(x)\n",
    "y_torch = torch.as_tensor(y)\n",
    "params = torch.tensor([0.5, 0.2, 0.2], requires_grad=True)\n",
    "kernel_torch = torch_rbf_kernel(var=params[0], l=params[1])\n",
    "mll = marg_log_likelihood(x_torch, y_torch, kernel_torch, var_n=params[2])\n",
    "print(params, mll)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([params], lr=0.05)\n",
    "epochs = 10\n",
    "all_mll = np.zeros(epochs+1)\n",
    "all_mll[0] = mll\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    (-mll).backward()\n",
    "    optimizer.step()\n",
    "    mll = marg_log_likelihood(x_torch, y_torch, kernel_torch, var_n=params[2])\n",
    "    all_mll[i+1] = mll.detach().numpy()\n",
    "print(params, mll)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_mll)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "kernel = rbf_kernel(params.detach().numpy()[0], params.detach().numpy()[1])\n",
    "mu, cov = gp_prediction(x[:, 1].reshape(-1, 1), y, x_star, kernel, params.detach().numpy()[2])\n",
    "ax.plot(x_star, mu)\n",
    "ax.fill_between(x_star.flatten(), mu-np.diag(cov), mu+np.diag(cov), alpha=0.3)\n",
    "ax.set_xlim(-1.5, 1.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}